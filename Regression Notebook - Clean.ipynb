{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From scratch example\n",
    "Source: https://machinelearningmastery.com/implement-simple-linear-regression-scratch-python/\n",
    "\n",
    "You can use something like this in the homework that I will publish in a few weeks\n",
    "\n",
    "In the homework, you will need to add a measurement of R^2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I downloaded the Swedish Insurance dataset and coverted to CSV and put it on github\n",
    "url = \"https://raw.githubusercontent.com/willwilson-sdsu/CS550/main/insurance.csv\"\n",
    "insurance_original = pd.read_csv(url)\n",
    "print(insurance_original.head())\n",
    "print(insurance_original.describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy so I dont need to keep pulling from web when I break things\n",
    "# Even though it is pretty small\n",
    "insurance = insurance_original.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example from https://machinelearningmastery.com/implement-simple-linear-regression-scratch-python/ that does stats from scratch\n",
    "# We will use a super basic example for this one then move to the insurance example and use Panda methods for that\n",
    "# Calculate the mean value of a list of numbers\n",
    "def mean(values):\n",
    "    return sum(values) / float(len(values))\n",
    " \n",
    "# Calculate the variance of a list of numbers\n",
    "def variance(values, mean):\n",
    "    return sum([(x-mean)**2 for x in values])\n",
    " \n",
    "# calculate mean and variance\n",
    "dataset = [[1.0, 1.0], [2.0, 3.0], [4.0, 3.0], [3.0, 2.0], [5.0, 5.0]]\n",
    "x = [float(row[0]) for row in dataset]\n",
    "y = [float(row[1]) for row in dataset]\n",
    "mean_x, mean_y = mean(x), mean(y)\n",
    "var_x, var_y = variance(x, mean_x), variance(y, mean_y)\n",
    "print('x stats: mean=%.3f variance=%.3f' % (mean_x, var_x))\n",
    "print('y stats: mean=%.3f variance=%.3f' % (mean_y, var_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate covariance between x and y\n",
    "def covariance(x, mean_x, y, mean_y):\n",
    "    covar = 0.0\n",
    "    for i in range(len(x)):\n",
    "        covar += (x[i] - mean_x) * (y[i] - mean_y)\n",
    "    return covar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covar = covariance(x, mean_x, y, mean_y)\n",
    "print('Covariance: %.3f' % (covar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate coefficients\n",
    "def coefficients(dataset):\n",
    "    x = [row[0] for row in dataset]\n",
    "    y = [row[1] for row in dataset]\n",
    "    x_mean, y_mean = mean(x), mean(y)\n",
    "    b1 = covariance(x, x_mean, y, y_mean) / variance(x, x_mean)\n",
    "    b0 = y_mean - b1 * x_mean\n",
    "    return [b0, b1]\n",
    "\n",
    "b0, b1 = coefficients(dataset)\n",
    "print('Coefficients: B0=%.3f, B1=%.3f' % (b0, b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check with Scitkitlearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np  \n",
    "x_np =  np.array([x]).reshape(5,1)\n",
    "y_np = np.array([y]).reshape(5,1)\n",
    "model = LinearRegression()\n",
    "model.fit(x_np,y_np)\n",
    "print(\"Coefficient:\",model.coef_)\n",
    "print(\"Y intercept:\",model.intercept_)\n",
    "print(\"Model R^2 score:\",model.score(x_np,y_np))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x_new = np.linspace(0, 10, 10)\n",
    "y_new = model.predict(x_new[:, np.newaxis]) # We can look at sklearn docs to get this syntax\n",
    "plt.figure(figsize=(4, 3))\n",
    "# Create the axes\n",
    "ax = plt.axes()\n",
    "ax.scatter(x_np, y_np)   # Add a plot of the points to the graph\n",
    "ax.plot(x_new, y_new) # Add the line to the graph\n",
    "\n",
    "ax.set_xlabel('x') # Set the labels\n",
    "ax.set_ylabel('y')\n",
    "# Look at documentation to see other options\n",
    "\n",
    "# Resize the axis so subgraphs wont overlap and things like that\n",
    "ax.axis('tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will do this again using the insurance data\n",
    "# Use Pandas to get stats\n",
    "\n",
    "def panda_coefficient(dataset):\n",
    "    x_mean = dataset['X'].mean()\n",
    "    y_mean = dataset['Y'].mean()\n",
    "    # Note - variance normalized by N-1 by default. This can be changed using the ddof argument\n",
    "    var_x= dataset.var(axis=0,ddof=0)['X']\n",
    "    cov_x_y = dataset.cov(ddof=0)['X']['Y']\n",
    "    b1 = cov_x_y / var_x\n",
    "    b0 = y_mean - b1 * x_mean\n",
    "    return [b0,b1]\n",
    "    \n",
    "b0, b1 = panda_coefficient(insurance)\n",
    "print('Coefficients: B0=%.3f, B1=%.3f' % (b0, b1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np  \n",
    "x_np = insurance.iloc[:, 0].values.reshape(-1, 1)  # values converts it into a numpy array\n",
    "y_np = insurance.iloc[:, 1].values.reshape(-1, 1)  # -1 means that calculate the dimension of rows, but have 1 column\n",
    "model_insurance = LinearRegression()\n",
    "model_insurance.fit(x_np,y_np)\n",
    "print(\"Coefficient:\",model_insurance.coef_)\n",
    "print(\"Y intercept:\",model_insurance.intercept_)\n",
    "print(\"Model score:\",model_insurance.score(x_np,y_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new = np.linspace(0, 120, 400)\n",
    "y_new = model_insurance.predict(x_new[:, np.newaxis]) # We can look at sklearn docs to get this syntax\n",
    "plt.figure(figsize=(4, 3))\n",
    "# Create the axes\n",
    "ax = plt.axes()\n",
    "ax.scatter(x_np, y_np)   # Add a plot of the points to the graph\n",
    "ax.plot(x_new, y_new) # Add the line to the graph\n",
    "\n",
    "ax.set_xlabel('x') # Set the labels\n",
    "ax.set_ylabel('y')\n",
    "# Look at documentation to see other options\n",
    "\n",
    "# Resize the axis so subgraphs wont overlap and things like that\n",
    "ax.axis('tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --user yellowbrick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residiuals\n",
    "# https://www.scikit-yb.org/en/latest/api/regressor/residuals.html\n",
    "\n",
    "# Create the train and test data\n",
    "#from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yellowbrick.regressor import ResidualsPlot\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x_np, y_np, test_size=0.2, random_state=42)\n",
    "# Not much data here, but we will see what we get\n",
    "model_ins2 =  LinearRegression()\n",
    "visualizer = ResidualsPlot(model_ins2)\n",
    "visualizer.fit(X_train, y_train)  # Fit the training data to the visualizer\n",
    "visualizer.score(X_test, y_test)  # Evaluate the model on the test data\n",
    "visualizer.show()                 # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "Now we want to classify data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you feel up to it, read through https://towardsdatascience.com/logistic-regression-detailed-overview-46c4da4303bc and manually set up the cost and activation functions.\n",
    "I am going to show a basic example using sklearn.\n",
    "For the homework (one assigned), I encourage you to look at the parameters in sklearn to improve your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull in the Iris dataset \n",
    "# This time we will grab it direct from sklearn\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "iris_values = iris['data']\n",
    "iris_target = iris['target']\n",
    "#.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using this example https://medium.com/@kgpvijaybg/logistic-regression-on-iris-dataset-48b2ecdfb6d3\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_values, iris_target, test_size = 0.25, random_state = 0)\n",
    "# This uses mulitple input values so we need to use a scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression(random_state = 0, solver='lbfgs', multi_class='auto')\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "# Predict probabilities\n",
    "probs_y=classifier.predict_proba(X_test)\n",
    "### Print results \n",
    "probs_y = np.round(probs_y, 2)\n",
    "res = \"{:<10} | {:<10} | {:<10} | {:<13} | {:<5}\".format(\"y_test\", \"y_pred\", \"Setosa(%)\", \"versicolor(%)\", \"virginica(%)\\n\")\n",
    "res += \"-\"*65+\"\\n\"\n",
    "res += \"\\n\".join(\"{:<10} | {:<10} | {:<10} | {:<13} | {:<10}\".format(x, y, a, b, c) for x, y, a, b, c in zip(y_test, y_pred, probs_y[:,0], probs_y[:,1], probs_y[:,2]))\n",
    "res += \"\\n\"+\"-\"*65+\"\\n\"\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very basic. \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "# confusion matrix sns heatmap \n",
    "ax = plt.axes()\n",
    "df_cm = cm\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 30}, fmt='d',cmap=\"Blues\", ax = ax )\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
